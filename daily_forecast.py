import os
import numpy as np
import pandas as pd
import requests
import joblib
import firebase_admin
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from firebase_admin import credentials, db
from datetime import datetime

# Import TensorFlow
import tensorflow as tf
from tensorflow import keras

# --- 1. C·∫§U H√åNH ---
SHEET_NAME = 'ESP32' 
WORKSHEET_NAME = 'Sheet1' 

DATABASE_URL = 'https://test-weather-station-default-rtdb.firebaseio.com/' 
LAT = 10.8231
LON = 106.6297
HISTORY_DAYS = 30 
FEATURE_COLS = ['Nhi·ªát ƒë·ªô', 'ƒê·ªô ·∫©m', '√Åp su·∫•t', 'T·ªëc ƒë·ªô gi√≥', 'H∆∞·ªõng gi√≥', 'L∆∞·ª£ng m∆∞a']

base_dir = os.path.dirname(os.path.abspath(__file__))
model_path = os.path.join(base_dir, 'weather_forecast_model.h5')
scaler_in_path = os.path.join(base_dir, 'scaler_features.joblib')
scaler_out_path = os.path.join(base_dir, 'scaler_targets_continuous.joblib')
key_path = os.path.join(base_dir, 'serviceAccountKey.json')

# --- H√ÄM CHUY·ªÇN ƒê·ªîI H∆Ø·ªöNG GI√ì ---
def convert_wind_direction(direction_str):
    try:
        d = str(direction_str).lower().strip()
        mapping = {
            'b·∫Øc': 0, 'b': 0, 'north': 0, 'n': 0,
            'ƒë√¥ng b·∫Øc': 45, 'ƒëb': 45, 'ne': 45,
            'ƒë√¥ng': 90, 'ƒë': 90, 'east': 90, 'e': 90,
            'ƒë√¥ng nam': 135, 'ƒën': 135, 'se': 135,
            'nam': 180, 'n': 180, 'south': 180, 's': 180,
            't√¢y nam': 225, 'tn': 225, 'sw': 225,
            't√¢y': 270, 't': 270, 'west': 270, 'w': 270,
            't√¢y b·∫Øc': 315, 'tb': 315, 'nw': 315
        }
        return mapping.get(d, 0)
    except:
        return 0

# --- 2. H√ÄM L·∫§Y D·ªÆ LI·ªÜU N·ªÄN (OPEN-METEO) ---
def get_open_meteo_backup():
    print("üåê ƒêang t·∫£i d·ªØ li·ªáu n·ªÅn t·ª´ Open-Meteo (Backup)...")
    url = f"https://api.open-meteo.com/v1/forecast?latitude={LAT}&longitude={LON}&hourly=temperature_2m,relative_humidity_2m,rain,surface_pressure,wind_speed_10m,wind_direction_10m&past_days=40&forecast_days=1"
    try:
        r = requests.get(url, timeout=10)
        r.raise_for_status()
        data = r.json()
        hourly = data['hourly']
        df = pd.DataFrame({
            'Ng√†y': pd.to_datetime(hourly['time']),
            'Nhi·ªát ƒë·ªô': hourly['temperature_2m'],
            'ƒê·ªô ·∫©m': hourly['relative_humidity_2m'],
            '√Åp su·∫•t': hourly['surface_pressure'],
            'T·ªëc ƒë·ªô gi√≥': hourly['wind_speed_10m'],
            'H∆∞·ªõng gi√≥': hourly['wind_direction_10m'],
            'L∆∞·ª£ng m∆∞a': hourly['rain']
        })
        df.set_index('Ng√†y', inplace=True)
        return df
    except Exception as e:
        print(f"‚ö†Ô∏è Kh√¥ng g·ªçi ƒë∆∞·ª£c Open-Meteo: {e}")
        return None

# --- 3. H√ÄM L·∫§Y D·ªÆ LI·ªÜU T·ª™ GOOGLE SHEET ---
def get_google_sheet_data():
    print("‚òÅÔ∏è ƒêang t·∫£i d·ªØ li·ªáu t·ª´ Google Sheet (ESP32)...")
    try:
        scope = ['https://spreadsheets.google.com/feeds', 'https://www.googleapis.com/auth/drive']
        creds = ServiceAccountCredentials.from_json_keyfile_name(key_path, scope)
        client = gspread.authorize(creds)
        sheet = client.open(SHEET_NAME).worksheet(WORKSHEET_NAME)
        data = sheet.get_all_records()
        
        if not data: return None

        df = pd.DataFrame(data)
        
        try:
            df['DateTimeStr'] = df['Date'].astype(str) + ' ' + df['Time'].astype(str)
            df['Ng√†y'] = pd.to_datetime(df['DateTimeStr'], errors='coerce')
        except Exception as e:
            print(f"‚ö†Ô∏è L·ªói x·ª≠ l√Ω ng√†y th√°ng Sheet: {e}")
            return None
            
        rename_map = {
            'Temperature': 'Nhi·ªát ƒë·ªô',
            'Humidity': 'ƒê·ªô ·∫©m',
            'Pressure': '√Åp su·∫•t',
            'Wind Speed': 'T·ªëc ƒë·ªô gi√≥',
            'Wind Direction': 'H∆∞·ªõng gi√≥',
            'Rainfall': 'L∆∞·ª£ng m∆∞a'
        }
        df.rename(columns=rename_map, inplace=True)
        
        if 'H∆∞·ªõng gi√≥' in df.columns:
            df['H∆∞·ªõng gi√≥'] = df['H∆∞·ªõng gi√≥'].apply(convert_wind_direction)
            
        df = df.dropna(subset=['Ng√†y'])
        df.set_index('Ng√†y', inplace=True)
        
        cols_numeric = ['Nhi·ªát ƒë·ªô', 'ƒê·ªô ·∫©m', '√Åp su·∫•t', 'T·ªëc ƒë·ªô gi√≥', 'H∆∞·ªõng gi√≥', 'L∆∞·ª£ng m∆∞a']
        for col in cols_numeric:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')
        
        df = df[df['Nhi·ªát ƒë·ªô'] > 0] 
        df = df[cols_numeric]
        
        print(f"‚úÖ ƒê√£ t·∫£i {len(df)} d√≤ng d·ªØ li·ªáu t·ª´ Sheet.")
        return df
        
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói ƒë·ªçc Google Sheet: {e}")
        return None

# --- 4. H√ÄM TR·ªòN D·ªÆ LI·ªÜU ---
def get_hybrid_data():
    df_meteo = get_open_meteo_backup()
    if df_meteo is None: return None
    
    df_esp32 = get_google_sheet_data()
    
    if df_esp32 is not None and not df_esp32.empty:
        print("‚ö° ƒêang gh√©p n·ªëi: ESP32 + Open-Meteo...")
        df_esp32_hourly = df_esp32.resample('H').mean()
        df_merged = df_esp32_hourly.combine_first(df_meteo)
    else:
        print("‚ö†Ô∏è D√πng 100% d·ªØ li·ªáu Open-Meteo.")
        df_merged = df_meteo
        
    df_daily = df_merged.resample('D').mean().dropna()
    
    if len(df_daily) < HISTORY_DAYS:
        print(f"‚ùå Kh√¥ng ƒë·ªß d·ªØ li·ªáu (C√≥ {len(df_daily)} ng√†y).")
        return None
        
    df_final = df_daily.iloc[-HISTORY_DAYS:][FEATURE_COLS]
    print(f"‚úÖ D·ªØ li·ªáu ƒë·∫ßu v√†o: {df_final.index[0].date()} -> {df_final.index[-1].date()}")
    return df_final.values

# --- 5. CH·∫†Y D·ª∞ B√ÅO ---
def run_forecast():
    print("\n--- B·∫ÆT ƒê·∫¶U QU√Å TR√åNH D·ª∞ B√ÅO ---")
    print("üì• ƒêang load Model & Scaler...")
    try:
        model = keras.models.load_model(model_path, compile=False)
        scaler_features = joblib.load(scaler_in_path)
        scaler_targets = joblib.load(scaler_out_path)
    except Exception as e:
        print(f"‚ùå L·ªói load file: {e}")
        return

    raw_data = get_hybrid_data()
    if raw_data is None: return
    
    input_scaled = scaler_features.transform(np.array(raw_data))
    current_window = input_scaled.reshape(1, HISTORY_DAYS, 6)
    
    firebase_results = {}
    print("\nüîÆ K·∫æT QU·∫¢ D·ª∞ B√ÅO 7 NG√ÄY T·ªöI (CH·ªà 1 KI·ªÇU TH·ªúI TI·∫æT):")
    print("="*85)
    
    for i in range(7):
        try:
            pred_raw = model.predict(current_window, verbose=0)
            pred_flat = np.array(pred_raw).flatten()
            last_6_values = pred_flat[-6:] 
            
            continuous_part = last_6_values[:3]
            boolean_part = last_6_values[3:] # [Score_N·∫Øng, Score_M∆∞a, Score_Gi√¥ng]
            
            real_continuous = scaler_targets.inverse_transform([continuous_part])[0]
            val_nhiet = float(real_continuous[0])
            val_am = float(real_continuous[1])
            val_mua = float(real_continuous[2])
            if val_mua < 0: val_mua = 0

            # --- LOGIC M·ªöI: CH·ªåN 1 TRONG 3 (MAX SCORE) ---
            # T√¨m xem ch·ªâ s·ªë n√†o (0, 1 hay 2) c√≥ ƒëi·ªÉm cao nh·∫•t
            max_idx = np.argmax(boolean_part)
            
            # Reset t·∫•t c·∫£ v·ªÅ False
            is_nang = False
            is_mua = False
            is_giong = False
            
            icon_str = ""
            
            # G√°n True cho ng∆∞·ªùi chi·∫øn th·∫Øng
            # Gi·∫£ ƒë·ªãnh th·ª© t·ª± l√† [N·∫Øng, M∆∞a, Gi√¥ng]
            if max_idx == 0:
                is_nang = True
                icon_str = "‚òÄÔ∏è Tr·ªùi N·∫Øng"
            elif max_idx == 1:
                is_mua = True
                icon_str = "üåßÔ∏è Tr·ªùi M∆∞a"
            elif max_idx == 2:
                is_giong = True
                icon_str = "‚õàÔ∏è C√≥ Gi√¥ng"

            day_key = f"Day_{i+1}"
            firebase_results[day_key] = {
                "nhietDo": round(val_nhiet, 1),
                "doAm": round(val_am, 1),
                "luongMua": round(val_mua, 2),
                "troiNang": is_nang,
                "troiMua": is_mua,
                "troiGiong": is_giong
            }
            
            # Hi·ªÉn th·ªã Terminal g·ªçn g√†ng
            print(f"üìÖ {day_key}: "
                  f"üå°Ô∏è {val_nhiet:.1f}¬∞C  |  "
                  f"üíß {val_am:.1f}%  |  "
                  f"üåßÔ∏è {val_mua:.2f}mm  |  "
                  f"{icon_str}")

            new_row = current_window[0, -1].copy()
            new_row[0] = continuous_part[0]
            new_row[1] = continuous_part[1]
            new_row[5] = continuous_part[2]
            current_window = np.append(current_window[:, 1:, :], [[new_row]], axis=1)
            
        except Exception as e:
            print(f"‚ùå L·ªói ng√†y {i+1}: {e}")
            return

    print("="*85)
    print("üì§ ƒêang g·ª≠i d·ªØ li·ªáu l√™n Firebase...")
    if not firebase_admin._apps:
        cred = credentials.Certificate(key_path)
        firebase_admin.initialize_app(cred, {'databaseURL': DATABASE_URL})
    
    ref = db.reference('weather_forecast')
    ref.set(firebase_results)
    print("‚úÖ HO√ÄN T·∫§T!")

if __name__ == "__main__":
    run_forecast()